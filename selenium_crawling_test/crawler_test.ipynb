{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_F6H8LGcl_2.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_BGJa9tQD_3-1.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_lPVoxDcB_4.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_lPVoxDcB_5.jpg\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_2KhZnBFi_5.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_u1NWlCya_2.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_6kcnvo3G_1.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_2KhZnBFi_4.jpg\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_nHYe54D9_4.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_8XcsbtFE_1.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_DbQBJ4fh_3.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_rhf5QLqc_5.jpg\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_4UZpyWgD_1.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_w57duI3A_7.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_o98v5zVU_8.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_AamtyriS_2.jpg\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_TLjiMsIk_1.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_XVIwR4Tl_2.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_c5pMSVoU_4.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_maMH95lF_8.jpg\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_Sm8WnpY7_2.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_op34Fu8m_4.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_g9SqyKEL_1.jpg\n",
      "http://img.yapen.co.kr/pension/room/27114/800x0/1893263282_JW5laper_3.jpg\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from urllib import parse\n",
    "\n",
    "\n",
    "# 사이드 메뉴 열 필요 없어서 일땐 빼놈. @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "# 여기 참고해서 작성해봤었음. https://brunch.co.kr/@jk-lab/18\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 지역별로 버튼 클릭할 필요없이 걍 다 담겨있네..\n",
    "# from selenium import webdriver\n",
    "\n",
    "# chromedriver_dir = '/home/nasanmaro/Desktop/projects/yapen/test/selenium_crawling_test/chromedriver'\n",
    "# driver = webdriver.Chrome(chromedriver_dir)\n",
    "# driver.get('http://www.yapen.co.kr')\n",
    "# time.sleep(5)\n",
    "\n",
    "# # 왼쪽 메뉴를 연다. \n",
    "# loca = driver.find_element_by_class_name('yapenMenu')\n",
    "# loca.click()\n",
    "# time.sleep(5)\n",
    "\n",
    "# # 드라이버 인스턴스로부터 현제 메뉴 연상태의 페이지 소스 받아서 source에 넣는다. \n",
    "# source = driver.page_source\n",
    "\n",
    "# # soup 객체로 만듬.\n",
    "# soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "\n",
    "\n",
    "# 이것까지 하면 사이드 메뉴여는것 됬다. \n",
    "##########뒤에 아직따라안한 부분.################################################\n",
    "\n",
    "\n",
    "# sido = driver.find_element_by_class_name('sido_area_box')\n",
    "# li = sido.find_elements_by_tag_name('li')\n",
    "# li[0].click()\n",
    "# time.sleep(5)\n",
    "\n",
    "# gugun = driver.find_element_by_class_name('gugun_area_box')\n",
    "# guli = gugun.find_element_by_tag_name('li')\n",
    "# guuli.click()\n",
    "# time.sleep(5)\n",
    "\n",
    "\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "# location_name_list 뽑는 과정 \n",
    "\n",
    "def location_name_list_crawler():\n",
    "    request = requests.get(\"http://www.yapen.co.kr\")\n",
    "    response = request.text\n",
    "    soup = BeautifulSoup(response, 'lxml')\n",
    "\n",
    "    left_menu=soup.select('div.locLayer')\n",
    "    # 풀빌라, MD추천 제외 14지역중 7지역 만남김.\n",
    "    selected_left_menu= left_menu[2:9]\n",
    "    \n",
    "\n",
    "    # 여기에 list 형태로 지역,지역고유번호/(세부지역,고유번호) 넣고싶다. \n",
    "    # location_name_list =[ [지역1 ,지역1고유번호 , [ (고유번호,세부지역),(고유번호2,세부지역2)...] ],\n",
    "    #                       [지역2 ,지역2고유번호 , [ (고유번호,세부지역),(고유번호2,세부지역2)...] ],..\n",
    "    location_name_list=list()\n",
    "\n",
    "    for location in selected_left_menu:\n",
    "        # 지역 이름 먼저 뽑음 \n",
    "        location_name = location.select('div.titleStyle')[0].get_text(strip=True)\n",
    "        location_name_sub_list=list()\n",
    "        location_name_sub_list.append(location_name)\n",
    "\n",
    "        li=location.select('li')\n",
    "\n",
    "        #for문 돌면서 (고유번호 세부지역) 리스트에 담은뒤 location_list에 넣겠다.\n",
    "        location_detail_list=[] \n",
    "        for location_detail in li:\n",
    "            onclick_value = location_detail['onclick']  #regionMove('1.003021','금산/논산');\n",
    "            \n",
    "            split_right = onclick_value.split(',')[0]\n",
    "            split_left = onclick_value.split(',')[1]\n",
    "\n",
    "            sub_location_no = re.findall(\"'(.+)'\",split_right)[0]\n",
    "            sub_location_name = re.findall(\"'(.+)'\",split_left)[0]\n",
    "\n",
    "            location_detail_tuple = (sub_location_no,sub_location_name)\n",
    "\n",
    "             # (고유번호/세부지역) 리스트에 담음\n",
    "            location_detail_list.append(location_detail_tuple)\n",
    "        \n",
    "        # 지역 고유번호부터 정규표현식으로 뽑아내서 담음.(세부지역 고유번호의 소숫점 뒤 3자리)\n",
    "        \n",
    "        location_detail_no_for_search = location_detail_list[0][0] # '1.003021'\n",
    "        location_detaol_no = re.findall(\".(\\d\\d\\d)\",location_detail_no_for_search)[0]\n",
    "        location_name_sub_list.append(location_detaol_no)\n",
    "        \n",
    "        # location_name_sub_list (고유번호 세부지역) 리스트를 넣음.\n",
    "        location_name_sub_list.append(location_detail_list)\n",
    "        \n",
    "        # 상위 리스트에 넣음 \n",
    "        location_name_list.append(location_name_sub_list)\n",
    "        \n",
    "    return location_name_list\n",
    "    \n",
    "    \n",
    "# location_dict 뽑는 과정 끝\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "#이제 각 페이지 location 가서 해커톤때 쓴 pension crawler 돌리고 싶다.\n",
    "# 메인페이지에서 기본정보 3개만 여러개 팬션에게서 가져왔던것.\n",
    "\n",
    "# url = \"http://www.yapen.co.kr/region?location=015&subLocation=1.015001\"\n",
    "\n",
    "def pension_crawler(location_no,sub_location_no):\n",
    "\n",
    "    params = {\n",
    "            'location':location_no,\n",
    "             'subLocation':sub_location_no,\n",
    "        }\n",
    "\n",
    "    url = \"http://www.yapen.co.kr/region?\" + parse.urlencode(params)\n",
    "\n",
    "    request = requests.get(url)\n",
    "    response = request.text\n",
    "    soup = BeautifulSoup(response, 'lxml')\n",
    "\n",
    "\n",
    "    title_list=list()\n",
    "    img_file_list=list()\n",
    "    price_list=list()\n",
    "    pldx_list=list()\n",
    "    discount_rate_list=list()\n",
    "\n",
    "    title_uls = soup.select('ul.dest-place-opt-fea')\n",
    "    for ul in title_uls:\n",
    "        li=ul.select('li')\n",
    "        title_list.append(li[1].get_text())\n",
    "\n",
    "    price_uls = soup.select('ul.dest-place-opt-cast')\n",
    "    for ul in price_uls:\n",
    "        li=ul.select('li')\n",
    "        price_list.append(li[1].get_text())\n",
    "\n",
    "\n",
    "    img_file_divs = soup.select('div.imgBox')\n",
    "    for div in img_file_divs:\n",
    "        img_file_list.append(div.select('img')[0]['src'])\n",
    "\n",
    "        list1 = re.split('/', div.select('img')[0]['src'])\n",
    "        pldx_list.append(int(list1[5]))\n",
    "\n",
    "\n",
    "    dest_place_pics = soup.select('div.dest-place-pic')\n",
    "    for dest_place_pic in dest_place_pics:\n",
    "        # dest_place_pic에는 dic가 2개 or 1게 있는데  discount_rate가 있는 경우는 div가 2개이며\n",
    "        # 길이가 5여서 이것으로 discount_rate있고 없고 를 비교한다. \n",
    "        if(len(dest_place_pic)==5):\n",
    "            discount_rate_string =dest_place_pic.select('div')[0].get_text(strip=True)\n",
    "            # %문자 정규표현식으로 빼줌.\n",
    "            discount_rate_int = int(re.search('(\\d*)',discount_rate_string).group())\n",
    "            discount_rate_list.append(discount_rate_int)\n",
    "        else:\n",
    "            discount_rate_list.append(0)\n",
    "\n",
    "\n",
    "    sub_locations_info_list = [title_list, price_list, img_file_list,pldx_list,discount_rate_list]\n",
    "    \n",
    "    return sub_locations_info_list\n",
    "        \n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "##province_name_list 로부터 지역명,고유번호 받아서 각 세부지역별로 pension_crawler \n",
    "## 해서 기본정보 3개씩 모으는 크롤러##\n",
    "\n",
    "def location_crawler():\n",
    "    \n",
    "    location_info_list=list()\n",
    "    \n",
    "    location_name_list = location_name_list_crawler()\n",
    "    # location_name_list =[ [지역1 ,지역1고유번호 , [ (고유번호,세부지역),(고유번호2,세부지역2)...] ],\n",
    "    #                       [지역2 ,지역2고유번호 , [ (고유번호,세부지역),(고유번호2,세부지역2)...] ],..\n",
    "    \n",
    "    for location in location_name_list:\n",
    "        location_name = location[0]\n",
    "        location_no = location[1]\n",
    "        sub_location_list = location[2]\n",
    "        for sub_location in sub_location_list:\n",
    "            print(sub_location)\n",
    "            sub_location_no = sub_location[0]\n",
    "            sub_location_name = sub_location[1]\n",
    "            sub_locations_info_list = pension_crawler(location_no, sub_location_no)\n",
    "            \n",
    "            #기존에 pension모델 1차적으로 이름,가격,이미지로  만들던것에\n",
    "            #location, sub_location 속성 추가해서 이곳에서 만들면 될듯하다.\n",
    "            # 일단은 리스트 형태로 정보 6개 묶어서 저장해보겠음.\n",
    "            #[[location,sub_location,title,pricem,img_file,pldx]....팬션 999까지 한 리스트에\n",
    "            \n",
    "            for i in range(len(sub_locations_info_list[0])):\n",
    "                location_info_list.append([location_name,\n",
    "                                           sub_location_name,\n",
    "                                           sub_locations_info_list[0][i],# title\n",
    "                                           sub_locations_info_list[1][i],# price\n",
    "                                           sub_locations_info_list[2][i],# img_file\n",
    "                                           sub_locations_info_list[3][i],# pldx\n",
    "                                           sub_locations_info_list[4][i]\n",
    "                                          ])\n",
    "    \n",
    "    return location_info_list\n",
    "    \n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "################pension-detail-crawler 작성중.################################################\n",
    "########\n",
    "######## 팬션별 세부정보 크롤링.\n",
    "\n",
    "# p테그 없는것 24140\n",
    "# 픽업가능타이틀,디테일 없는경우, 이용주의사항 디테일만 없는경우 32928\n",
    "# 픽업가능타이틀,디테일 없는경우, 27114\n",
    "# 픽업가능 있는경우 20405\n",
    "\n",
    "import json\n",
    "\n",
    "params = {\n",
    "    'ypIdx':  27114\n",
    "}\n",
    "\n",
    "url = \"http://www.yapen.co.kr/details?\" + parse.urlencode(params)\n",
    "\n",
    "request = requests.get(url)\n",
    "response = request.text\n",
    "soup = BeautifulSoup(response, 'lxml')\n",
    "\n",
    "# name \n",
    "name_root = soup.select('div.wrap_1000')\n",
    "name = name_root[0].select('h3')[0].get_text()\n",
    "\n",
    "# address \n",
    "table = soup.select('table.pensionTbl')\n",
    "trs = table[0].select('tr')\n",
    "tds = trs[0].select('td')\n",
    "address = tds[0].get_text()\n",
    "\n",
    "# check_in, check_out \n",
    "tds2 = trs[1].select('td')\n",
    "check_in_out = tds2[0].select('span')\n",
    "check_in = check_in_out[0].get_text()\n",
    "check_out = check_in_out[1].get_text()\n",
    "\n",
    "# pickup\n",
    "tds3 = trs[2].select('td')\n",
    "pickup = tds3[0].get_text(strip=True)\n",
    "\n",
    "# room_num\n",
    "td4 = trs[3].select('td')\n",
    "number_tags = td4[0].select('span')\n",
    "room_string = number_tags[0].get_text()\n",
    "room_num = int(re.search('(\\d*)',room_string).group())\n",
    "\n",
    "# info\n",
    "td5 = trs[4].select('td')\n",
    "infos = td5[0].select('p')\n",
    "info = ''\n",
    "for one_info in infos:\n",
    "    info = info + '\\n' + one_info.get_text() + '\\n'\n",
    "\n",
    "# theme \n",
    "td6 = trs[5].select('td')\n",
    "lis = td6[0].select('li')\n",
    "theme_list = []\n",
    "for li in lis:\n",
    "    theme_list.append(li.get_text() )\n",
    "theme = json.dumps(theme_list)\n",
    "\n",
    "\n",
    "# room_name_list = list()##############################\n",
    "# image_table = soup.select('div.roomImageLists')\n",
    "# image_table_lis = image_table[0].select('li')\n",
    "# for index,image_table_li in enumerate(image_table_lis):\n",
    "#     if 0<index<room_num+1:\n",
    "#         room_name_list.append(image_table_li.get_text())\n",
    "        \n",
    "        \n",
    "# pension_detail 페이지 하단 추가정보들 . \n",
    "detailDiv = soup.select('div.detailDiv')[0]\n",
    "detailsPensionInfoTitle = detailDiv.select('div.detailsPensionInfoTitle')\n",
    "\n",
    "pension_detail_bellow_dict = dict()\n",
    "for one_title in detailsPensionInfoTitle:\n",
    "    next_detail_div = one_title.findNext('div')\n",
    "    next_detail=''\n",
    "    for p in next_detail_div.select('p'):\n",
    "        next_detail= next_detail + p.get_text() +'\\n'\n",
    "    # p 테그없고 바로 text쓴경우에는 검출안된다.....         \n",
    "    pension_detail_bellow_dict[one_title.get_text(strip=True)] = next_detail\n",
    "\n",
    "\n",
    "check_in_out_detail = \"\"\n",
    "pickup_detail = \"\"\n",
    "gretting = \"\"\n",
    "precautions = \"\" \n",
    "\n",
    "\n",
    "for key, value in pension_detail_bellow_dict.items():\n",
    "    if key == '입실 / 퇴실시간':\n",
    "        check_in_out_detail = value\n",
    "    elif key == '픽업가능':\n",
    "        pickup_detail = value\n",
    "    elif key == '펜션소개 및 인사말':\n",
    "        gretting = value\n",
    "    elif key == '이용 주의사항':\n",
    "        precautions =  value\n",
    "            \n",
    "# print(name)\n",
    "# print(address)\n",
    "# print(check_in)\n",
    "# print(check_out)\n",
    "# print(room_num)\n",
    "# print(info_result)\n",
    "# print(theme)\n",
    "\n",
    "# print(check_in_out_detail)\n",
    "# print(pickup_detail) \n",
    "# print(gretting)\n",
    "# print(precautions) \n",
    "        \n",
    "        \n",
    "# address = \n",
    "# check_in =\n",
    "# check_out =\n",
    "# pickup = \n",
    "# room_num = \n",
    "# info =\n",
    "# theme = \n",
    "# coordinate = \n",
    "\n",
    "# # pension-detail 페이지 하단부 이용안내 부분.\n",
    "# check_in_out_detail \n",
    "# pickup_detail \n",
    "# gretting \n",
    "# precautions \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Room 모델 정보, RoomImage 모델 체우기 위한 이미지 셀레늄으로 뽑아보겠슴.\n",
    "\n",
    "# 일단 방 이름부터 뽑아내겠슴. \n",
    "room_name_list = []\n",
    "image_table = soup.select('div.roomImageLists')\n",
    "image_table_lis = image_table[0].select('li')\n",
    "for index,image_table_li in enumerate(image_table_lis):\n",
    "    if 0<index<room_num+1:\n",
    "        room_name_list.append(image_table_li.get_text())\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "# 접속.\n",
    "chromedriver_dir = '/home/nasanmaro/Desktop/projects/yapen/test/selenium_crawling_test/chromedriver'\n",
    "driver = webdriver.Chrome(chromedriver_dir)\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "# 방갯수만큼의 버튼을 클릭!\n",
    "# \n",
    "image_table = driver.find_element_by_class_name('roomImageLists')\n",
    "for room_name_text in room_name_list:           # room_name_text----------->Room객체만들때 써라 \n",
    "    room_name_button = image_table.find_elements_by_xpath(f\"//*[contains(text(), '{room_name_text}')]\")\n",
    "    room_name_button[0].click()\n",
    "    time.sleep(5) #버튼 클릭후 충분히 멈춰줘야 사진이 로딩된다. \n",
    "    \n",
    "    # 드라이버 인스턴스로부터 현제 메뉴 연상태의 페이지 소스 받아서 source에 넣는다. \n",
    "    source = driver.page_source\n",
    "    # soup 객체로 만듬.\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "    \n",
    "    pensionImagesLists = soup.find(id=\"pensionImagesLists\")\n",
    "    jssorts=pensionImagesLists.select_one('div.jssort07')\n",
    "    jssort = jssorts.select('div')[0]\n",
    "    image_tags = jssort.select('div.p > img')\n",
    "    \n",
    "    for index,image_tag in enumerate(image_tags):\n",
    "        image_src = image_tag.get(\"src\")\n",
    "        print(image_src)                        #image_src------------>RoomImage객체만들때써라\n",
    "        if index == 2: #3장 뽑는 시점에서 break\n",
    "            break\n",
    "                                              #이for문안에서RoomImage객체 room마다 총세번 만들면될듯\n",
    "                \n",
    "    print('@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "    \n",
    "                                                \n",
    "    print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "    \n",
    "driver.close()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 지역별로 버튼 클릭할 필요없이 걍 다 담겨있네..\n",
    "# from selenium import webdriver\n",
    "\n",
    "# chromedriver_dir = '/home/nasanmaro/Desktop/projects/yapen/test/selenium_crawling_test/chromedriver'\n",
    "# driver = webdriver.Chrome(chromedriver_dir)\n",
    "# driver.get('http://www.yapen.co.kr')\n",
    "# time.sleep(5)\n",
    "\n",
    "# # 왼쪽 메뉴를 연다. \n",
    "# loca = driver.find_element_by_class_name('yapenMenu')\n",
    "# loca.click()\n",
    "# time.sleep(5)\n",
    "\n",
    "# # 드라이버 인스턴스로부터 현제 메뉴 연상태의 페이지 소스 받아서 source에 넣는다. \n",
    "# source = driver.page_source\n",
    "\n",
    "# # soup 객체로 만듬.\n",
    "# soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "##########뒤에 아직따라안한 부분.################################################\n",
    "\n",
    "\n",
    "# sido = driver.find_element_by_class_name('sido_area_box')\n",
    "# li = sido.find_elements_by_tag_name('li')\n",
    "# li[0].click()\n",
    "# time.sleep(5)\n",
    "\n",
    "# gugun = driver.find_element_by_class_name('gugun_area_box')\n",
    "# guli = gugun.find_element_by_tag_name('li')\n",
    "# guuli.click()\n",
    "# time.sleep(5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# room_name_list = list()##############################\n",
    "# image_table = soup.select('div.roomImageLists')\n",
    "# image_table_lis = image_table[0].select('li')\n",
    "# for index,image_table_li in enumerate(image_table_lis):\n",
    "#     if 0<index<room_num+1:\n",
    "#         room_name_list.append(image_table_li.get_text())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  해커톤때 모델저장하는것 크롤러에서 다해버렸는데 추후에 여기 참고하면 좋을듯.\n",
    "\n",
    "\n",
    "#  params = {\n",
    "#         'ypIdx': ypIdx\n",
    "#     }\n",
    "\n",
    "#     url = \"http://www.yapen.co.kr/details?\" + parse.urlencode(params)\n",
    "\n",
    "#     request = requests.get(url)\n",
    "#     response = request.text\n",
    "#     soup = BeautifulSoup(response, 'lxml')\n",
    "\n",
    "#     name_root = soup.select('div.wrap_1000')\n",
    "#     name = name_root[0].select('h3')[0].get_text()\n",
    "\n",
    "#     table = soup.select('table.pensionTbl')\n",
    "#     trs = table[0].select('tr')\n",
    "#     tds = trs[0].select('td')\n",
    "#     address = tds[0].get_text()\n",
    "\n",
    "#     tds2 = trs[1].select('td')\n",
    "#     check_in_out = tds2[0].select('span')\n",
    "#     check_in = check_in_out[0].get_text()\n",
    "#     check_out = check_in_out[1].get_text()\n",
    "\n",
    "#     td3 = trs[3].select('td')\n",
    "#     number_tags = td3[0].select('span')\n",
    "#     room = number_tags[0].get_text()\n",
    "\n",
    "#     td4 = trs[4].select('td')\n",
    "#     infos = td4[0].select('p')\n",
    "#     info_result = ''\n",
    "#     for info in infos:\n",
    "#         info_result = info_result + '\\n' + info.get_text() + '\\n'\n",
    "\n",
    "#     td5 = trs[5].select('td')\n",
    "#     lis = td5[0].select('li')\n",
    "#     theme_result = ''\n",
    "#     for li in lis:\n",
    "#         theme_result = theme_result + '\\n' + li.get_text() + '\\n'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "#@@@@@@@@@@@@@@@@@@@@@실행창 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "# province_name_list = province_name_list_crawler()\n",
    "# print(province_name_list)\n",
    "\n",
    "# test = location_name_list_crawler()\n",
    "# print(test)\n",
    "\n",
    "# test = pension_crawler('015','1.015001')\n",
    "# print(test)\n",
    "\n",
    "\n",
    "# location_info_list = location_crawler()\n",
    "# print(location_info_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
